{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explore different combinations of the features that were used in submission and save the results/evaluations to compare the different scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import bioc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../final_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import annotation\n",
    "import base_feature\n",
    "import made_utils\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "from nltk import ngrams as nltk_ngrams\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/Users/alec/Data/NLP_Challenge'\n",
    "# ALLDIR = os.path.join(DATADIR, 'original_data')\n",
    "TRAINDIR = os.path.join(DATADIR, 'MADE-1.0')\n",
    "TESTDIR = os.path.join(DATADIR, 'made_test_data')\n",
    "print(os.path.exists(TRAINDIR))\n",
    "print(os.path.exists(TESTDIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep\n",
    "First, here are some functions that we'll define. They are defined elsewhere in the package, but we'll include them here for simplicity's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_grams(ngram_string):\n",
    "    \"\"\"\n",
    "    Normalizes the values in a string of joined ngrams\n",
    "    \"\"\"\n",
    "    # Substitute numbers\n",
    "    ngram_string = re.sub('[\\d]+|one|two|three|four|five|six|seven|eight|nine|ten', '<NUMBER>', ngram_string)\n",
    "    return ngram_string\n",
    "\n",
    "\n",
    "\n",
    "class LexicalFeatureExtractor(base_feature.BaseFeatureExtractor):\n",
    "    \"\"\"This class will create a set of features from a Relation object\n",
    "    and return a dictionary of features that can later be vectorized.\n",
    "    \n",
    "    ngram_window - the length of ngrams to include in the vocabulary.\n",
    "    context_window - the number of ngrams to include before and after the entity.\n",
    "    \"\"\"\n",
    "    def __init__(self, ngram_window=(1, 1), context_window=(2, 2),\n",
    "                vocab=None, pos_vocab=None, min_vocab_count=5, min_pos_count=5):\n",
    "        super().__init__()\n",
    "        self.ngram_window = ngram_window\n",
    "        if min(ngram_window) < 1 or max(ngram_window) > 3:\n",
    "            raise NotImplementedError(\"Ngram Window must be between one and 3\")\n",
    "        self.context_window = context_window\n",
    "        self.min_vocab_count = min_vocab_count\n",
    "        self.min_pos_count = min_pos_count\n",
    "\n",
    "        # Set vocab and POS vocab\n",
    "        self._unfiltered_vocab = vocab # Contains unigrams-trigrams, no count threshold\n",
    "        self._unfiltered_pos_vocab = pos_vocab\n",
    "\n",
    "        self.vocab = self.create_vocab(vocab, min_vocab_count, self.ngram_window) # Only contains ngrams defined by context_window\n",
    "        #print(self.vocab); exit()\n",
    "        self.pos_vocab =  self.create_vocab(pos_vocab, min_pos_count, self.ngram_window)\n",
    "        #self.tokens = [gram for (gram, idx) in self.vocab.items() if len(gram.split()) == 1] # Only unigrams\n",
    "        self.pos = {} # Will eventually contain mapping for POS tags\n",
    "\n",
    "        # pyConText tools\n",
    "        #self.modifiers = itemData.instantiateFromCSVtoitemData(\"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/lexical_kb_05042016.tsv\")\n",
    "        #self.targets = itemData.instantiateFromCSVtoitemData(\"https://raw.githubusercontent.com/abchapman93/MADE_relations/master/feature_extraction/targets.tsv?token=AUOYx9rYHO6A5fiZS3mB9e_3DP83Uws8ks5aownVwA%3D%3D\")\n",
    "\n",
    "\n",
    "        #self.all_features_values = self.create_base_features()\n",
    "\n",
    "\n",
    "\n",
    "    def create_base_features(self):\n",
    "        \"\"\"\n",
    "        Enumerates possible feature values from the vocab, as well as an OOV value.\n",
    "        Any features that are binary should only get one index and are encoded as 0.\n",
    "        \"\"\"\n",
    "        # This will be a dictionary that contains all possible values for each feature\n",
    "        all_features_values = {\n",
    "            'same_sentence': 0,\n",
    "            'num_tokens_between': 0,\n",
    "            'grams_between': ['OOV'] + list(self.vocab),\n",
    "            'grams_before': ['OOV'] + list(self.vocab),\n",
    "            'grams_after': ['OOV'] + list(self.vocab),\n",
    "            'pos_grams_between': ['OOV'] + list(self.pos_vocab),\n",
    "            #'pos_grams_before': ['OOV'] + list(self.pos_vocab),\n",
    "            #'pos_grams_after': ['OOV'] + list(self.pos_vocab),\n",
    "            'first_entity_type': 0,#list(ENTITY_TYPES_MAPPING.values()),\n",
    "            'second_entity_type': 0,#list(ENTITY_TYPES_MAPPING.values()),\n",
    "\n",
    "            }\n",
    "        return all_features_values\n",
    "\n",
    "    def create_feature_dict(self, relat, doc, entities=True, entities_between=True, surface=True):\n",
    "        \"\"\"\n",
    "        Takes a RelationAnnotation and an AnnotatedDocument.\n",
    "        Returns the a dictionary containing the defined lexical features.\n",
    "        \"\"\"\n",
    "\n",
    "        lex_features = {}\n",
    "\n",
    "        if entities:\n",
    "            lex_features.update(self.get_entity_features(relat, doc))\n",
    "        if entities_between:\n",
    "            lex_features.update(self.get_entities_between_features(relat, doc))\n",
    "        if surface:\n",
    "            lex_features.update(self.get_surface_features(relat, doc))\n",
    "        return lex_features\n",
    "    \n",
    "    \n",
    "    def get_entity_features(self, relat, doc):\n",
    "        features = {}\n",
    "        \n",
    "        # The full string of the entities\n",
    "        anno1, anno2 = relat.get_annotations()\n",
    "        features['text_in_anno1'] = anno1.text.lower()\n",
    "        features['text_in_anno2'] = anno2.text.lower()\n",
    "        features['concat_text'] = anno1.text.lower() + ':' + anno2.text.lower()\n",
    "        \n",
    "        # Features for types of the entities\n",
    "        features['first_entity_type:<{}>'.format(relat.entity_types[0].upper())] = 1\n",
    "        features['second_entity_type:<{}>'.format(relat.entity_types[1].upper())] = 1\n",
    "        \n",
    "        # Feature types for entities, left to right\n",
    "        sorted_entities = sorted((relat.annotation_1, relat.annotation_2), key=lambda a: a.span[0])\n",
    "        features['entity_types_concat'] = '<=>'.join(['<{}>'.format(a.type.upper()) for a in sorted_entities])\n",
    "        return features\n",
    "    \n",
    "    \n",
    "    def get_entities_between_features(self, relat, doc):\n",
    "       \n",
    "        features = {}\n",
    "        # One binary feature for every type of entity between\n",
    "        entities_between = self.get_entities_between(relat, doc)\n",
    "        # TODO: Maybe change this to a count\n",
    "        features.update({\n",
    "            'entities_between:<{}>'.format(v.type.upper()): 1 for v in entities_between\n",
    "            })\n",
    "        features['num_entities_between'] = len(entities_between)\n",
    "\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_surface_features(self, relat, doc):        \n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Same sentence\n",
    "        features['num_sentences_overlap'] = len(doc.get_sentences_overlap_span(relat.get_span()))\n",
    "        # Get the number of tokens between\n",
    "        # NOTE: only unigrams\n",
    "        \n",
    "        features['num_tokens_between'] = len(self.get_grams_between(relat, doc, ngram_window=(1, 1)))\n",
    "        # Get all tokens/POS tags in between\n",
    "        # Create one feature for each ngram/tag\n",
    "        features.update({\n",
    "            'grams_between:<{}>'.format(v): 1 for v in self.get_grams_between(relat, doc)\n",
    "            })\n",
    "        features.update({\n",
    "            'grams_before:<{}>'.format(v): 1 for v in self.get_grams_before(relat, doc)\n",
    "            })\n",
    "        features.update({\n",
    "            'grams_after:<{}>'.format(v): 1 for v in self.get_grams_after(relat, doc)\n",
    "            })\n",
    "\n",
    "        features.update({\n",
    "            'tags_between:<{}>'.format(v): 1 for v in self.get_grams_between(relat, doc, seq='tags')\n",
    "            })\n",
    "        features.update({\n",
    "            'tags_before:<{}>'.format(v): 1 for v in self.get_grams_before(relat, doc, seq='tags')\n",
    "            })\n",
    "        features.update({\n",
    "            'tags_after:<{}>'.format(v): 1 for v in self.get_grams_after(relat, doc, seq='tags')\n",
    "            })\n",
    "\n",
    "        # Get features for information about entities/context between\n",
    "        # Binary feature: Are they in the same sentence?\n",
    "        features['same_sentence'] = doc.in_same_sentence(relat.get_span())\n",
    "        return features\n",
    "        \n",
    "\n",
    "    def get_grams_between(self, relat, doc, seq='tokens', ngram_window=None):\n",
    "        \"\"\"\n",
    "        Returns the N-grams between the two entities connected in relat.\n",
    "        Represents it as OOV if it's not in the vocabulary.\n",
    "        Returns a unique set.\n",
    "        \"\"\"\n",
    "\n",
    "        if seq == 'tokens':\n",
    "            vocab = self.vocab\n",
    "        elif seq == 'tags':\n",
    "            vocab = self.pos_vocab\n",
    "        else:\n",
    "            raise ValueError(\"Must specify seq: {}\".format(seq))\n",
    "\n",
    "        if not ngram_window:\n",
    "            ngram_window = self.ngram_window\n",
    "\n",
    "        all_grams = []\n",
    "        span1, span2 = relat.spans\n",
    "        # Fixed this: get the start and span of the middle, not of the entire relation\n",
    "        _, start, end, _ = sorted(span1 +span2)\n",
    "        tokens_in_span = doc.get_tokens_or_tags_at_span((start, end), seq)\n",
    "        # NOTE: lower-casing the ngrams, come back to this if you want to encode the casing\n",
    "        tokens_in_span = [token.lower() for token in tokens_in_span]\n",
    "        for n in range(ngram_window[0], ngram_window[1] + 1):\n",
    "            # Now sort the ngrams so that it doesn't matter what order they occur in\n",
    "            grams = list(nltk_ngrams(tokens_in_span, n))\n",
    "            grams = self.sort_ngrams(grams)# + [' '.join(sorted(tup)) for tup in list(nltk_ngrams(tokens_in_span, n))]\n",
    "            all_grams.extend(set(grams))\n",
    "        all_grams = [self.normalize_grams(x) for x in set(all_grams)]\n",
    "        all_grams = [x if x in vocab else 'OOV' for x in all_grams]\n",
    "        return set(all_grams)\n",
    "\n",
    "\n",
    "    def get_grams_before(self, relat,doc, seq='tokens', ngram_window=None):\n",
    "        \"\"\"\n",
    "        Returns the n-grams before the first entity.\n",
    "        \"\"\"\n",
    "        if seq == 'tokens':\n",
    "            vocab = self.vocab\n",
    "        elif seq == 'tags':\n",
    "            vocab = self.pos_vocab\n",
    "        if not ngram_window:\n",
    "            ngram_window = self.ngram_window\n",
    "\n",
    "        all_grams = []\n",
    "        offset = relat.span[0]\n",
    "        tokens_before = doc.get_tokens_or_tags_before_or_after(offset, delta=-1,\n",
    "            n=self.context_window[0], seq=seq, padding=True)\n",
    "        tokens_before = [token.lower() for token in tokens_before]\n",
    "        for n in range(ngram_window[0], ngram_window[1] + 1):\n",
    "            grams = list(nltk_ngrams(tokens_before, n))\n",
    "            grams = self.sort_ngrams(grams)# + [' '.join(sorted(tup)) for tup in list(nltk_ngrams(tokens_in_span, n))]\n",
    "            all_grams.extend(set(grams))\n",
    "            #grams = grams + [' '.join(sorted(tup)) for tup in list(nltk_ngrams(tokens_before, n))]\n",
    "        all_grams = [self.normalize_grams(x) for x in set(all_grams)]\n",
    "        all_grams = [x if x in vocab else 'OOV' for x in all_grams]\n",
    "        return set(all_grams)\n",
    "\n",
    "    def get_grams_after(self, relat, doc, seq='tokens', ngram_window=None):\n",
    "        \"\"\"\n",
    "        Returns the n-grams after the final entity.\n",
    "        \"\"\"\n",
    "        if seq == 'tokens':\n",
    "            vocab = self.vocab\n",
    "        elif seq == 'tags':\n",
    "            vocab = self.pos_vocab\n",
    "        if not ngram_window:\n",
    "            ngram_window = self.ngram_window\n",
    "\n",
    "        all_grams = []\n",
    "        offset = relat.span[1]\n",
    "        tokens_after = doc.get_tokens_or_tags_before_or_after(offset, delta=1,\n",
    "                                        n=self.context_window[1], seq=seq)\n",
    "        tokens_after = [token.lower() for token in tokens_after]\n",
    "        for n in range(ngram_window[0], ngram_window[1] + 1):\n",
    "            grams = list(nltk_ngrams(tokens_after, n))\n",
    "            grams = self.sort_ngrams(grams)# + [' '.join(sorted(tup)) for tup in list(nltk_ngrams(tokens_in_span, n))]\n",
    "            all_grams.extend(set(grams))\n",
    "            #grams = grams + [' '.join(sorted(tup)) for tup in list(nltk_ngrams(tokens_after, n))]\n",
    "        all_grams = [self.normalize_grams(x) for x in set(all_grams)]\n",
    "        all_grams = [x if x in vocab else 'OOV' for x in all_grams]\n",
    "        return set(all_grams)\n",
    "\n",
    "    def sort_ngrams(self, ngrams):\n",
    "        return [' '.join(sorted(tup)) for tup in ngrams]\n",
    "\n",
    "    def normalize_grams(self, ngram_string):\n",
    "        \"\"\"\n",
    "        Normalizes the values in a string of joined ngrams\n",
    "        \"\"\"\n",
    "        # Substitute numbers\n",
    "        return normalize_grams(ngram_string)\n",
    "\n",
    "    def get_pos_tags(self):\n",
    "        pass\n",
    "\n",
    "    def get_entities_between(self, relat, doc):\n",
    "        \"\"\"\n",
    "        Returns a list of entities that occur between entity1 and entity2\n",
    "        \"\"\"\n",
    "        offset, end = relat.get_span()\n",
    "        overlapping_entities = []\n",
    "        # Index the entity in doc by span\n",
    "        offset_to_entity = {entity.span[0]: entity for entity in doc.get_annotations()\n",
    "                    if entity.id not in (\n",
    "                        relat.annotation_1.id, relat.annotation_2.id)\n",
    "                        }\n",
    "\n",
    "        while offset < end:\n",
    "            if offset in offset_to_entity:\n",
    "                overlapping_entities.append(offset_to_entity[offset])\n",
    "            offset += 1\n",
    "\n",
    "        return overlapping_entities\n",
    "\n",
    "\n",
    "    def get_sent_with_anno(self, anno, doc, entity_type):\n",
    "        \"\"\"\n",
    "        Returns the sentence that contains a given annotation.\n",
    "        Replaces the text of the annotations with a tag <ENTITY-TYPE>\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        # Step back some window\n",
    "        offset = anno.start_index\n",
    "\n",
    "        while offset not in doc._sentences:\n",
    "            offset -= 1\n",
    "            if offset < 0:\n",
    "                break\n",
    "            if offset in doc._tokens:\n",
    "                tokens.insert(0, doc._tokens[offset].lower())\n",
    "\n",
    "        # Now add an entity\n",
    "        tokens.append(entity_type)\n",
    "\n",
    "        # Now add all the tokens between them\n",
    "        offset = anno.start_index\n",
    "\n",
    "        while offset not in doc._sentences:\n",
    "            if offset > max(doc._tokens.keys()):\n",
    "                break\n",
    "            if offset in doc._tokens:\n",
    "                tokens.append(doc._tokens[offset].lower())\n",
    "            offset += 1\n",
    "\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"LexicalFeatureExtractor Ngram Window: {} Vocab: {} terms\".format(\n",
    "                self.ngram_window, len(self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_annotations_in_doc(doc, legal_edges=[], max_sent_length=3):\n",
    "    \"\"\"\n",
    "    Takes a single AnnotatedDocument that contains annotations.\n",
    "    All annotations that have a legal edge between them\n",
    "    and are have an overlapping sentence length <= max_sent_length,\n",
    "        ie., they are in either the same sentence or n adjancent sentences,\n",
    "    are paired to create RelationAnnotations.\n",
    "    Takes an optional list legal_edges that defines which edges should be allowed.\n",
    "\n",
    "    Returns a list of new RelationAnnotations with annotation type 'none'.\n",
    "    \"\"\"\n",
    "    if legal_edges == []:\n",
    "        legal_edges = [('Drug', 'Route'),\n",
    "                         ('Drug', 'Indication'),\n",
    "                         ('SSLIF', 'Severity'),\n",
    "                         ('Drug', 'Dose'),\n",
    "                         ('Drug', 'Frequency'),\n",
    "                         ('Drug', 'Duration'),\n",
    "                         ('Drug', 'ADE'),\n",
    "                         ('ADE', 'Severity'),\n",
    "                         ('Indication', 'Severity'),\n",
    "                         ('SSLIF', 'ADE')]\n",
    "    true_annotations = doc.get_annotations()\n",
    "    true_relations = doc.get_relations()\n",
    "    generated_relations = []\n",
    "    edges = defaultdict(list)\n",
    "    edges = set()\n",
    "\n",
    "    # Map all annotation_1's to annotation_2's\n",
    "    # in order to identify all positive examples of relations\n",
    "    # If this is testing data, it may not actually have these\n",
    "    for relat in true_relations:\n",
    "        anno1, anno2 = relat.get_annotations()\n",
    "        edges.add((anno1.id, anno2.id))\n",
    "\n",
    "    for anno1 in true_annotations:\n",
    "        for anno2 in true_annotations:\n",
    "\n",
    "            # Don't pair the same annotation with itself\n",
    "            if anno1.id == anno2.id:\n",
    "                continue\n",
    "\n",
    "            if anno1.span == anno2.span:\n",
    "                continue\n",
    "\n",
    "            # Don't generate paris that have already been paried\n",
    "            if (anno1.id, anno2.id) in edges:\n",
    "                continue\n",
    "\n",
    "            # Exclude illegal relations\n",
    "            if len(legal_edges) and (anno1.type, anno2.type) not in legal_edges:\n",
    "                continue\n",
    "\n",
    "            # Check the span between them, make sure it's either 1 or 2\n",
    "            start1, end1 = anno1.span\n",
    "            start2, end2 = anno2.span\n",
    "            sorted_spans = list(sorted([start1, end1, start2, end2]))\n",
    "            span = (sorted_spans[0], sorted_spans[-1])\n",
    "            overlapping_sentences = doc.get_sentences_overlap_span(span)\n",
    "            if len(overlapping_sentences) > max_sent_length:\n",
    "                continue\n",
    "\n",
    "            # If they haven't already been paired, pair them\n",
    "            else:\n",
    "                generated_relation = annotation.RelationAnnotation.from_null_rel(\n",
    "                    anno1, anno2, doc.file_name\n",
    "                )\n",
    "                edges.add((anno1.id, anno2.id))\n",
    "                generated_relations.append(generated_relation)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return list(set(generated_relations + true_relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neg_relations(docs, neg_prop=2):\n",
    "    \"\"\"\n",
    "    Takes a list of Relationannotations and\n",
    "    neg_prop, a float that specifies the proportion of negative\n",
    "    to positive examples.\n",
    "    If the documents don't have relations, ie., are test documents,\n",
    "    neg_prop should be False and it will take all negative relations \n",
    "    as possible relations.\n",
    "    \"\"\"\n",
    "    relations = []\n",
    "    for i, (fname, doc) in enumerate(docs.items()):\n",
    "        if i  % 10 == 0:\n",
    "            print('-{}: {} '.format(i, fname))\n",
    "            print(len(doc.relations))\n",
    "        new_relations = pair_annotations_in_doc(doc)\n",
    "\n",
    "        # Add Fake relations for training\n",
    "        neg_relations = set(new_relations).difference(set(doc.relations))\n",
    "        # Sample them\n",
    "        if neg_prop and len(neg_relations) >= neg_prop * len(doc.relations):\n",
    "            neg_relations = random.sample(neg_relations, neg_prop * len(doc.relations))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        doc.add_relations(neg_relations)\n",
    "\n",
    "        relations.extend(doc.get_relations())\n",
    "        if i  % 10 == 0:\n",
    "            print(len(doc.get_relations()))\n",
    "    return relations\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dicts(relations, docs):\n",
    "    \"\"\"\n",
    "    Iterates through a list of relations.\n",
    "    Returns a list of feature dicts\n",
    "    \"\"\"\n",
    "    feat_dicts = []\n",
    "    for i, r in enumerate(relations):\n",
    "        doc = docs[r.file_name]\n",
    "        if i % 100 == 0:\n",
    "            print(\"{}/{}\".format(i, len(relations)))\n",
    "        feat_dict = feature_extractor.create_feature_dict(r, doc, entities=True, entities_between=True, surface=True)\n",
    "        feat_dicts.append(feat_dict)\n",
    "        \n",
    "        \n",
    "    return feat_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "Relations with gold-standard annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "reader = made_utils.TextAndBioCParser(TRAINDIR)\n",
    "docs = reader.read_texts_and_xmls(-1) # TODO: Change to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs['12_123']\n",
    "doc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Cache for training\n",
    "with open('tmp_data/all_training_docs_and_relations.pkl', 'wb') as f:\n",
    "    pickle.dump((docs, relations), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_data/all_training_docs_and_relations.pkl', 'rb') as f:\n",
    "    docs, relations = pickle.load(f)\n",
    "len(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtypes = [r.type for r in relations]\n",
    "from collections import Counter\n",
    "c = Counter(rtypes)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the vocabulary that will be used for features\n",
    "with open('../final_system/data/vocab.pkl', 'rb') as f:\n",
    "    vocab, pos_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_extractor = LexicalFeatureExtractor(context_window=(2, 2),\n",
    "                            ngram_window=(1, 3), vocab=vocab, pos_vocab=pos_vocab,\n",
    "                            min_vocab_count=20, min_pos_count=20)\n",
    "feat_dicts = create_feature_dicts(relations, docs)\n",
    "\n",
    "print(len(feat_dicts))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Cache for training\n",
    "with open('tmp_data/feat_dicts.pkl', 'wb') as f:\n",
    "    pickle.dump(feat_dicts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_data/feat_dicts.pkl', 'rb') as f:\n",
    "    feat_dicts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_dicts[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform into vectors for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full = [r.type for r in relations]\n",
    "y_bin = ['any' if y_ != 'none' else y_ for y_ in y_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer(sparse=True, sort=True)\n",
    "k=1000\n",
    "\n",
    "binary_feature_selector = base_feature.MyFeatureSelector(vectorizer, k=k)\n",
    "full_feature_selector = base_feature.MyFeatureSelector(vectorizer, k=k)\n",
    "\n",
    "# Fit the vectorizer and feature selectors, transform X\n",
    "X_vector = vectorizer.fit_transform(feat_dicts)\n",
    "print(X_vector.shape)\n",
    "try:\n",
    "    binary_feature_selector = base_feature.MyFeatureSelector(vectorizer, k=k)\n",
    "    X_bin = binary_feature_selector.fit_transform(X_vector, y_bin)\n",
    "\n",
    "\n",
    "    full_feature_selector = base_feature.MyFeatureSelector(vectorizer, k=k)\n",
    "    X_full = full_feature_selector.fit_transform(X_vector, y_full) \n",
    "except ValueError as e: # Not enough features if only working with a few docs\n",
    "    binary_feature_selector = base_feature.MyFeatureSelector(vectorizer, k='all')\n",
    "    X_bin = binary_feature_selector.fit_transform(X_vector, y_bin)\n",
    "\n",
    "    full_feature_selector = base_feature.MyFeatureSelector(vectorizer, k='all')\n",
    "    X_full = full_feature_selector.fit_transform(X_vector, y_full) \n",
    "    \n",
    "print(X_bin.shape, X_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can train and evaluate each set\n",
    "def train_clf(X, y, cross_val=False):\n",
    "    \"\"\"\n",
    "    Trains and validates a model.\n",
    "    If cross_val is true, will first cross-validate\n",
    "    and report the scores\n",
    "    and return the unfitted classifier.\n",
    "    Otherwise, trains on the data and returns the fitted classifier.\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(max_depth = None,\n",
    "                            max_features = None,\n",
    "                            min_samples_leaf = 2,\n",
    "                            min_samples_split = 2,\n",
    "                            n_estimators = 10,\n",
    "                            n_jobs = 1)\n",
    "    print(X.shape)\n",
    "    if cross_val:\n",
    "        # Cross-validate to make sure this is going right\n",
    "        pred = cross_val_predict(clf, X, y, verbose=1)\n",
    "        print(classification_report(y, pred))\n",
    "#     clf.fit(X, y)\n",
    "    else:\n",
    "        clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary\n",
    "train_clf(X_bin, y_bin, cross_val=True)\n",
    "\n",
    "# Full\n",
    "train_clf(X_full, y_full, cross_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train on all of the data\n",
    "# Binary\n",
    "clf_bin = train_clf(X_bin, y_bin, cross_val=False)\n",
    "\n",
    "# Full\n",
    "clf_full = train_clf(X_full, y_full, cross_val=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data, clfs, vectorizers, feature_selectors\n",
    "with open('tmp_data/training_data.pkl', 'wb') as f:\n",
    "    pickle.dump(((X_bin, y_bin), (X_full, y_full)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_data/clfs.pkl', 'wb') as f:\n",
    "    pickle.dump((clf_bin, clf_full), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_data/vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "    \n",
    "with open('tmp_data/feature_selectors.pkl', 'wb') as f:\n",
    "    pickle.dump((binary_feature_selector, full_feature_selector), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Testing Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('tmp_data/test_docs.pkl', 'rb') as f:\n",
    "    test_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the test data\n",
    "test_reader = made_utils.TextAndBioCParser(TESTDIR)\n",
    "test_docs = test_reader.read_texts_and_xmls(-1, include_relations=False) # TODO: Change to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in clfs, vectorizers, feature extractors\n",
    "with open('tmp_data/clfs.pkl', 'rb') as f:\n",
    "    clf_bin, clf_full = pickle.load(f)\n",
    "    \n",
    "with open('tmp_data/vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "    \n",
    "with open('tmp_data/feature_selectors.pkl', 'rb') as f:\n",
    "    binary_feature_selector, full_feature_selector = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_data/test_docs.pkl', 'wb') as f:\n",
    "    pickle.dump(test_docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_relations = add_neg_relations(test_docs, False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_relations = []\n",
    "for i, (fname, doc) in enumerate(test_docs.items()):\n",
    "    if i  % 10 == 0:\n",
    "        print('-{}: {} '.format(i, fname))\n",
    "        print(len(doc.relations))\n",
    "    doc.relations = []\n",
    "    possible_relations = pair_annotations_in_doc(doc)\n",
    "    \n",
    "        \n",
    "    doc.add_relations(possible_relations)\n",
    "    \n",
    "    test_relations.extend(doc.get_relations())\n",
    "    if i  % 10 == 0:\n",
    "        print(len(doc.get_relations()))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_data/test_docs_and_relations.pkl', 'wb') as f:\n",
    "    pickle.dump((test_relations, test_docs), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create feature_dicts\n",
    "test_feat_dicts = create_feature_dicts(test_relations, test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test_relations[-1]\n",
    "feat_dict = test_feat_dicts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_feat_dicts)\n",
    "X_test_bin = binary_feature_selector.transform(X_test)\n",
    "X_test_full = full_feature_selector.transform(X_test)\n",
    "print(X_test_bin.shape)\n",
    "print(X_test_full.shape)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_bin = clf_bin.predict(X_test_bin)\n",
    "y_pred_full = clf_full.predict(X_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_data/preds.pkl', 'wb') as f:\n",
    "    pickle.dump((y_pred_bin, y_pred_full), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bioc_xml(doc, outdir):\n",
    "    \"\"\"\n",
    "    Writes an AnnotatedDocument to a .bioc.xml file\n",
    "    That can be used with the bioc_evaluation.py file\n",
    "    \"\"\"\n",
    "    outpath = os.path.join(outdir, doc.file_name + '.bioc.xml')\n",
    "    writer = bioc.BioCXMLWriter()\n",
    "    writer.collection = bioc.BioCCollection()\n",
    "    \n",
    "    collection = writer.collection\n",
    "    document = bioc.BioCDocument()\n",
    "    document.id = doc.file_name\n",
    "\n",
    "    passage = bioc.BioCPassage()\n",
    "    passage.offset = '0'\n",
    "    document.add_passage(passage)\n",
    "    collection.add_document(document)\n",
    "\n",
    "    # Add annotations that already have bioc annotations\n",
    "    for anno in doc.get_annotations():\n",
    "        passage.add_annotation(anno.bioc_anno)\n",
    "\n",
    "    for relat in doc.get_relations():\n",
    "        # Create new BioCRelation\n",
    "        relation = bioc.bioc_relation.BioCRelation()\n",
    "        relation.id = relat.id\n",
    "        relation.put_infon('type', relat.type)\n",
    "\n",
    "        # Reference that nodes that contain the annotations\n",
    "        node1 = bioc.bioc_node.BioCNode()\n",
    "        node1.role = 'annotation 1'\n",
    "        node1.refid = relat.annotation_1.id\n",
    "        relation.add_node(node1)\n",
    "\n",
    "        node2 = bioc.bioc_node.BioCNode()\n",
    "        node2.role = 'annotation 2'\n",
    "        node2.refid = relat.annotation_2.id\n",
    "        relation.add_node(node2)\n",
    "\n",
    "        passage.add_relation(relation)\n",
    "\n",
    "    writer.write(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out bioc annotations\n",
    "# Remove any duplicates that somehow got in\n",
    "def write_bioc_results(pred, relations, docs, outdir):\n",
    "    \"\"\"\n",
    "    Adds predicted relation types to relations\n",
    "    And filters out relations with a 'none' prediction label.\n",
    "    Removes any duplicates and writes out to outdir.\n",
    "    \"\"\"\n",
    "    for doc in docs.values():\n",
    "        doc.relations = []\n",
    "        existing_annos = set()\n",
    "        to_add = []\n",
    "        for i, anno in enumerate(doc.annotations):\n",
    "            if anno.id not in existing_annos:\n",
    "                to_add.append(anno)\n",
    "                existing_annos.add(anno.id)\n",
    "        doc.annotations = to_add\n",
    "\n",
    "    from collections import defaultdict\n",
    "    relations_already_seen = []\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        p = y_pred_test[i]\n",
    "    #     print(p); break\n",
    "        r = relations[i]\n",
    "        r.type = p\n",
    "        doc = test_docs[r.file_name]\n",
    "        if r.type != 'none':\n",
    "            doc.relations.append(r)\n",
    "\n",
    "\n",
    "    for doc in docs.values():\n",
    "        existing_relats = set()\n",
    "        to_add = []\n",
    "        for i, relat in enumerate(doc.relations):\n",
    "            if relat.id not in existing_relats:\n",
    "                to_add.append(relat)\n",
    "                existing_relats.add(relat.id)\n",
    "        doc.relations = to_add\n",
    "\n",
    "    \n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    for d in docs.values():\n",
    "        to_bioc_xml(d, outdir)\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = [y_pred_full[i] if y_pred_bin[i] != 'none' else 'none' for  i in range(len(y_pred_full))]\n",
    "y_pred_test\n",
    "outdir = 'tmp_data/output_{}'.format('test_set_task_one')\n",
    "write_bioc_results(y_pred_test, test_relations, test_docs, outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same with Kelly's output\n",
    "# Read in the test data\n",
    "KELLYDIR = '/Users/alec/Data/NLP_Challenge/task1_test_set_predictions'\n",
    "task_3_reader = made_utils.TextAndBioCParser(KELLYDIR)\n",
    "task_3_docs = task_3_reader.read_texts_and_xmls(-1, include_relations=False) # TODO: Change to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = task_3_docs['1_1069']\n",
    "doc.annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_3_relations = add_neg_relations(task_3_docs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_3_feat_dicts = create_feature_dicts(task_3_relations, task_3_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(task_3_feat_dicts)\n",
    "X_test_bin = binary_feature_selector.transform(X_test)\n",
    "X_test_full = full_feature_selector.transform(X_test)\n",
    "print(X_test_bin.shape)\n",
    "print(X_test_full.shape)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_bin = clf_bin.predict(X_test_bin)\n",
    "y_pred_full = clf_full.predict(X_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = [y_pred_full[i] if y_pred_bin[i] != 'none' else 'none' for  i in range(len(y_pred_full))]\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'tmp_data/output_{}'.format('test_set_task_three')\n",
    "write_bioc_results(y_pred_test, task_3_relations, task_3_docs, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
